# @package _global_

defaults:
  - override /pruning: unstructured_pruning.yaml
  - override /model: bert_base_uncased_pruned.yaml
  - override /datamodule: qqp.yaml

name: pruning/vanilla_then_prune
seed: 42

model:
  loss_fn: "reweight-by-teacher"
  from_checkpoint: null
  use_bias_probs: True
  freeze_weights: True

datamodule:
  bias_path: null
  batch_size: 128

trainer:
  max_epochs: 12
  gpus: 1
