# @package _global_

defaults:
  - override /pruning: unstructured_pruning.yaml
  - override /model: bert_base_uncased_pruned.yaml
  - override /datamodule: qqp.yaml

name: pruning/vanilla_then_prune
seed: 42

model:
  loss_fn: "reweight-by-teacher"
  from_checkpoint: "/remote/csifs1/disk0/meissner/shortcut-pruning/experiments/baselines/bert/qqp/multiruns/2022-05-19/11-25-19/0/checkpoints/last.ckpt"
  warmup_steps: 5000
  use_bias_probs: True
  freeze_weights: True

datamodule:
  bias_path: "/home/meissner/shortcut-pruning/data/weak_models/tinybert/qqp/tiny-qqp-10.json"
  batch_size: 128

trainer:
  max_epochs: 12
  gpus: 1
