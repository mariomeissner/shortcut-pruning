# @package _global_

defaults:
  - override /pruning: unstructured_pruning.yaml
  - override /model: bert_base_uncased_pruned.yaml
  - override /datamodule: mnli.yaml

name: pruning/vanilla_then_prune
seed: 42

model:
  loss_fn: "reweight-by-teacher"
  from_checkpoint: "/remote/csifs1/disk0/meissner/shortcut-pruning/experiments/baselines/bert/mnli/multiruns/2022-04-18/13-07-56/4/checkpoints/last.ckpt"
  use_bias_probs: True
  freeze_weights: True

datamodule:
  bias_path: "/home/meissner/shortcut-pruning/data/weak_models/utama/mnli_shallow_2K_fixed.json"
  batch_size: 128

trainer:
  max_epochs: 12
  gpus: 1
